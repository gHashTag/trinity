"use strict";(globalThis.webpackChunkdocsite=globalThis.webpackChunkdocsite||[]).push([[7326],{9734(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"getting-started/tutorial","title":"Tutorial: Build a Semantic Memory","description":"Learn Trinity\'s core operations by building a simple knowledge store that can answer questions.","source":"@site/docs/getting-started/tutorial.md","sourceDirName":"getting-started","slug":"/getting-started/tutorial","permalink":"/trinity/docs/getting-started/tutorial","draft":false,"unlisted":false,"editUrl":"https://github.com/gHashTag/trinity/tree/main/docsite/docs/getting-started/tutorial.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Quick Start","permalink":"/trinity/docs/getting-started/quickstart"},"next":{"title":"Installation","permalink":"/trinity/docs/getting-started/installation"}}');var t=i(4848),r=i(8453);const o={sidebar_position:2},a="Tutorial: Build a Semantic Memory",l={},c=[{value:"What We Will Build",id:"what-we-will-build",level:2},{value:"Step 1: Create Random Vectors",id:"step-1-create-random-vectors",level:2},{value:"Step 2: Bind Facts",id:"step-2-bind-facts",level:2},{value:"Step 3: Bundle into Memory",id:"step-3-bundle-into-memory",level:2},{value:"Step 4: Query the Memory",id:"step-4-query-the-memory",level:2},{value:"What Just Happened?",id:"what-just-happened",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"tutorial-build-a-semantic-memory",children:"Tutorial: Build a Semantic Memory"})}),"\n",(0,t.jsx)(n.p,{children:"Learn Trinity's core operations by building a simple knowledge store that can answer questions."}),"\n",(0,t.jsx)(n.p,{children:"Most AI systems need expensive GPUs and millions of training examples to learn facts. Trinity's Vector Symbolic Architecture takes a different approach. You can store and retrieve knowledge using simple math on ternary vectors. No training loop. No neural network. No GPU. This tutorial shows you how."}),"\n",(0,t.jsx)(n.h2,{id:"what-we-will-build",children:"What We Will Build"}),"\n",(0,t.jsx)(n.p,{children:'We will build a knowledge store that remembers facts like "France\'s capital is Paris" and can answer the question "What is France\'s capital?" The entire system runs in a single Zig file with zero dependencies beyond Trinity.'}),"\n",(0,t.jsx)(n.admonition,{title:"Key Insight",type:"tip",children:(0,t.jsx)(n.p,{children:"VSA memory works like a hologram. Every fact is spread across the entire vector. You can store many facts in one vector and query any of them individually."})}),"\n",(0,t.jsx)(n.p,{children:"Here is the pipeline we will follow:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-mermaid",children:'graph LR\n  A["Create Concept Vectors"] --\x3e B["Bind Facts"]\n  B --\x3e C["Bundle into Memory"]\n  C --\x3e D["Query with Unbind"]\n  D --\x3e E["Find Best Match"]\n'})}),"\n",(0,t.jsx)(n.h2,{id:"step-1-create-random-vectors",children:"Step 1: Create Random Vectors"}),"\n",(0,t.jsxs)(n.p,{children:["Every concept in our system gets its own random ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"hypervector"}),". Random vectors in high dimensions have a useful property: they are almost always unrelated to each other. Mathematicians call this ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"quasi-orthogonal"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-zig",children:'const vsa = @import("vsa.zig");\n\n// Create vectors for concepts\nvar france = vsa.randomVector(1000, 1);\nvar paris = vsa.randomVector(1000, 2);\nvar germany = vsa.randomVector(1000, 3);\nvar berlin = vsa.randomVector(1000, 4);\nvar role_capital = vsa.randomVector(1000, 100);\n\n// Random vectors are nearly orthogonal (unrelated)\nconst sim = vsa.cosineSimilarity(&france, &paris);\n// Output: sim \u2248 0.01 (essentially zero \u2014 unrelated concepts)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Each call to ",(0,t.jsx)(n.code,{children:"randomVector"})," takes two arguments: the number of ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"dimensions"})," and a seed. The seed ensures reproducible results. With 1000 dimensions, any two random vectors will have near-zero ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"cosine similarity"}),"."]}),"\n",(0,t.jsx)(n.admonition,{title:"Why 1000 Dimensions?",type:"tip",children:(0,t.jsx)(n.p,{children:"Higher dimensions give cleaner separations between unrelated concepts. At 1000 dimensions, random vectors reliably have similarity below 0.05. At 100 dimensions, collisions become more likely. For production systems, 4000-10000 dimensions are common."})}),"\n",(0,t.jsx)(n.h2,{id:"step-2-bind-facts",children:"Step 2: Bind Facts"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"Binding"})," links two concepts together. It works like a key-value pair: one vector is the key and the other is the value. The bound result is dissimilar to both inputs."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-zig",children:'// Create "capital" facts by binding role to city, then country to role-city\nvar fact1 = vsa.bind(&role_capital, &paris);\nvar binding1 = vsa.bind(&france, &fact1);\n// binding1 now encodes: "France \u2192 capital \u2192 Paris"\n\nvar fact2 = vsa.bind(&role_capital, &berlin);\nvar binding2 = vsa.bind(&germany, &fact2);\n// binding2 now encodes: "Germany \u2192 capital \u2192 Berlin"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Binding uses element-wise multiplication of ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"trits"}),". When you multiply two trits:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"+1 * +1 = +1"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"+1 * -1 = -1"})}),"\n",(0,t.jsxs)(n.li,{children:["Anything ",(0,t.jsx)(n.code,{children:"* 0 = 0"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The result scrambles both input patterns. That is why the bound vector is dissimilar to either input on its own."}),"\n",(0,t.jsx)(n.h2,{id:"step-3-bundle-into-memory",children:"Step 3: Bundle into Memory"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"Bundling"})," combines multiple vectors into one. Unlike binding, the result stays similar to all of its inputs. Think of it as superimposing facts on top of each other."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-zig",children:"// Combine both facts into a single memory vector\nvar memory = vsa.bundle2(&binding1, &binding2);\n// memory holds both facts simultaneously\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Bundling uses a ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"majority vote"})," at each position. For two vectors, ties (where the trits differ) are broken randomly. Despite this lossy compression, the signal from each input survives because the vectors are so high-dimensional."]}),"\n",(0,t.jsx)(n.admonition,{title:"Capacity Limits",type:"warning",children:(0,t.jsx)(n.p,{children:"A single memory vector can hold roughly the square root of its dimension count in facts. A 1000-dimensional vector stores around 30 facts reliably. Beyond that, the noise floor rises and retrieval accuracy drops. Increase dimensions for larger knowledge bases."})}),"\n",(0,t.jsx)(n.h2,{id:"step-4-query-the-memory",children:"Step 4: Query the Memory"}),"\n",(0,t.jsxs)(n.p,{children:['Now for the magic. To ask "What is France\'s capital?", we construct a query and ',(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"unbind"})," it from memory."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-zig",children:"// Construct query: bind France with capital role\nvar query = vsa.bind(&france, &role_capital);\n\n// Unbind query from memory to get noisy answer\nvar answer = vsa.unbind(&memory, &query);\n\n// Compare answer to known cities\nconst sim_paris = vsa.cosineSimilarity(&answer, &paris);\nconst sim_berlin = vsa.cosineSimilarity(&answer, &berlin);\n// Output: sim_paris \u2248 0.35, sim_berlin \u2248 0.02\n// Paris wins! The memory correctly recalls the capital.\n"})}),"\n",(0,t.jsx)(n.p,{children:"The answer vector is noisy because the memory also contains the Germany-Berlin fact. But the signal for Paris is strong enough to stand out clearly. The correct answer always has the highest similarity."}),"\n",(0,t.jsx)(n.admonition,{title:"How Unbinding Works",type:"tip",children:(0,t.jsxs)(n.p,{children:["Unbinding is the inverse of binding. Because binding uses multiplication and trits are their own inverses (",(0,t.jsx)(n.code,{children:"-1 * -1 = +1"}),"), unbinding is actually the same operation as binding. When you unbind the query from memory, you cancel out the France and role_capital patterns, leaving behind a noisy version of Paris."]})}),"\n",(0,t.jsx)(n.h2,{id:"what-just-happened",children:"What Just Happened?"}),"\n",(0,t.jsx)(n.p,{children:"Here is a summary of the four operations you just used:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Operation"}),(0,t.jsx)(n.th,{children:"Purpose"}),(0,t.jsx)(n.th,{children:"Analogy"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"randomVector"})}),(0,t.jsx)(n.td,{children:"Create a concept"}),(0,t.jsx)(n.td,{children:"A unique word in a dictionary"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"bind"})}),(0,t.jsx)(n.td,{children:"Link two concepts"}),(0,t.jsx)(n.td,{children:"A key-value pair"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"bundle2"})}),(0,t.jsx)(n.td,{children:"Combine facts into memory"}),(0,t.jsx)(n.td,{children:"Superimposing holograms"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"unbind"})," + ",(0,t.jsx)(n.code,{children:"cosineSimilarity"})]}),(0,t.jsx)(n.td,{children:"Retrieve an answer"}),(0,t.jsx)(n.td,{children:"Looking up a key, finding closest match"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:"The entire system has these properties:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No training."})," Facts are stored instantly with a single operation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No neural network."})," Pure vector algebra handles storage and retrieval."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No GPU needed."})," Ternary operations are additions and sign flips."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Constant-time retrieval."})," Query cost does not grow with the number of stored facts."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Fixed memory footprint."})," One vector holds many facts. A 1000-trit vector uses about 200 bytes in ",(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"packed mode"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"You now understand the core building blocks of Trinity's VSA engine. Here is where to go next:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/api/vsa",children:"VSA API Reference"})," -- full documentation of bind, bundle, permute, and similarity functions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/api/hybrid",children:"HybridBigInt Storage"})," -- learn about packed and unpacked modes for efficient memory use"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/api/sequence-hdc",children:"Sequence HDC"})," -- encode text as hypervectors using n-grams and permutations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/concepts/glossary",children:"Glossary"})," -- quick reference for all Trinity terminology"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);