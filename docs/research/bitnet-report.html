<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-research/bitnet-report" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">BitNet b1.58 Coherence Report | Trinity</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://gHashTag.github.io/trinity/docs/img/trinity-social-card.png"><meta data-rh="true" name="twitter:image" content="https://gHashTag.github.io/trinity/docs/img/trinity-social-card.png"><meta data-rh="true" property="og:url" content="https://gHashTag.github.io/trinity/docs/research/bitnet-report"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="BitNet b1.58 Coherence Report | Trinity"><meta data-rh="true" name="description" content="Authors: Trinity Research Team"><meta data-rh="true" property="og:description" content="Authors: Trinity Research Team"><link data-rh="true" rel="icon" href="/trinity/docs/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://gHashTag.github.io/trinity/docs/research/bitnet-report"><link data-rh="true" rel="alternate" href="https://gHashTag.github.io/trinity/docs/research/bitnet-report" hreflang="en"><link data-rh="true" rel="alternate" href="https://gHashTag.github.io/trinity/docs/research/bitnet-report" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"BitNet b1.58 Coherence Report","item":"https://gHashTag.github.io/trinity/docs/research/bitnet-report"}]}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"><link rel="stylesheet" href="/trinity/docs/assets/css/styles.469fa185.css">
<script src="/trinity/docs/assets/js/runtime~main.c8c765da.js" defer="defer"></script>
<script src="/trinity/docs/assets/js/main.496369f7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/trinity/docs/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/trinity/docs/"><div class="navbar__logo"><img src="/trinity/docs/img/logo.svg" alt="Trinity Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/trinity/docs/img/logo.svg" alt="Trinity Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Trinity</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/trinity/docs/">Documentation</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/gHashTag/trinity" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/"><span title="Trinity Documentation" class="linkLabel_WmDU">Trinity Documentation</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/overview/introduction"><span title="Overview" class="categoryLinkLabel_W154">Overview</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/getting-started/quickstart"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/concepts"><span title="Concepts" class="categoryLinkLabel_W154">Concepts</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/bitnet"><span title="BitNet Integration" class="categoryLinkLabel_W154">BitNet Integration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/hdc"><span title="HDC Applications" class="categoryLinkLabel_W154">HDC Applications</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/vibee"><span title="VIBEE Language" class="categoryLinkLabel_W154">VIBEE Language</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/benchmarks"><span title="Benchmarks" class="categoryLinkLabel_W154">Benchmarks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/deployment"><span title="Deployment" class="categoryLinkLabel_W154">Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/api"><span title="API Reference" class="categoryLinkLabel_W154">API Reference</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/architecture/overview"><span title="Architecture" class="categoryLinkLabel_W154">Architecture</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/math-foundations"><span title="Mathematical Foundations" class="categoryLinkLabel_W154">Mathematical Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/trinity/docs/research"><span title="Research" class="categoryLinkLabel_W154">Research</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/research"><span title="Research and References" class="linkLabel_WmDU">Research and References</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/trinity/docs/research/bitnet-report"><span title="BitNet b1.58 Coherence Report" class="linkLabel_WmDU">BitNet b1.58 Coherence Report</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/research/trinity-node-ffi"><span title="Trinity Node BitNet FFI Integration" class="linkLabel_WmDU">Trinity Node BitNet FFI Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/research/bibliography"><span title="Scientific Bibliography" class="linkLabel_WmDU">Scientific Bibliography</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/research/references"><span title="Scientific References" class="linkLabel_WmDU">Scientific References</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/faq"><span title="FAQ" class="linkLabel_WmDU">FAQ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/contributing"><span title="Contributing to Trinity" class="linkLabel_WmDU">Contributing to Trinity</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/trinity/docs/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Research</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">BitNet b1.58 Coherence Report</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>BitNet b1.58 Coherence Report</h1></header>
<div class="paper-meta"><p><strong>Authors:</strong> Trinity Research Team</p><p><strong>Date:</strong> February 5, 2026</p><p><strong>Status:</strong> Technical Report</p><p><strong>Model:</strong> microsoft/bitnet-b1.58-2B-4T</p></div>
<div class="abstract"><div class="abstract-title">Abstract</div><p>This report documents the results of testing Microsoft&#x27;s official BitNet b1.58-2B-4T model across three different inference frameworks: HuggingFace Transformers (greedy and sampling modes) and the official bitnet.cpp. We evaluate output coherence, inference speed, and practical usability of ternary-weight language models. Initial testing on CPU hardware (Apple M1 Pro) revealed incoherent output across all frameworks, attributed to GGUF tokenizer metadata errors. Subsequent GPU testing (RTX 4090) confirmed coherent text generation is achievable with proper configuration.</p><div class="keywords"><p><strong>Keywords:</strong> BitNet, ternary inference, LLM evaluation, 1.58-bit quantization, coherence testing</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="academic-references">Academic References<a href="#academic-references" class="hash-link" aria-label="Direct link to Academic References" title="Direct link to Academic References" translate="no">​</a></h2>
<ul>
<li class=""><strong>Ma et al. (2024)</strong> - &quot;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&quot; - <a href="https://arxiv.org/abs/2402.17764" target="_blank" rel="noopener noreferrer" class="">arXiv:2402.17764</a></li>
<li class=""><strong>Microsoft (2024)</strong> - &quot;BitNet b1.58 2B4T Technical Report&quot; - <a href="https://arxiv.org/abs/2504.12285" target="_blank" rel="noopener noreferrer" class="">arXiv:2504.12285</a></li>
<li class=""><strong>Microsoft (2024)</strong> - &quot;1-bit AI Infra: Fast and Lossless BitNet b1.58 Inference&quot; - <a href="https://arxiv.org/abs/2410.16144" target="_blank" rel="noopener noreferrer" class="">arXiv:2410.16144</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-specifications">Model Specifications<a href="#model-specifications" class="hash-link" aria-label="Direct link to Model Specifications" title="Direct link to Model Specifications" translate="no">​</a></h2>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>Model ID</td><td>microsoft/bitnet-b1.58-2B-4T</td></tr><tr><td>Parameters</td><td>2,412,820,480 (2.4B)</td></tr><tr><td>Hidden size</td><td>2560</td></tr><tr><td>Layers</td><td>30</td></tr><tr><td>Attention heads</td><td>20 (KV heads: 5, GQA ratio: 4)</td></tr><tr><td>FFN size</td><td>6912</td></tr><tr><td>Vocabulary size</td><td>128,256 (LLaMA 3 tokenizer)</td></tr><tr><td>Quantization</td><td>Native 1.58-bit ternary (I2_S)</td></tr><tr><td>Context length</td><td>4,096 tokens</td></tr><tr><td>RoPE frequency base</td><td>500,000</td></tr><tr><td>File size</td><td>1.10 GiB (GGUF), 1.18 GB (safetensors)</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="test-environment">Test Environment<a href="#test-environment" class="hash-link" aria-label="Direct link to Test Environment" title="Direct link to Test Environment" translate="no">​</a></h2>
<ul>
<li class=""><strong>Hardware:</strong> Apple M1 Pro (ARM64, 8 cores, no CUDA GPU)</li>
<li class=""><strong>OS:</strong> macOS Darwin 23.6.0</li>
<li class=""><strong>Compiler:</strong> Homebrew Clang 18.1.8</li>
<li class=""><strong>Python:</strong> 3.9 (conda environment) / 3.12 (system)</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="test-results">Test Results<a href="#test-results" class="hash-link" aria-label="Direct link to Test Results" title="Direct link to Test Results" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="test-1-huggingface-transformers-greedy-decoding">Test 1: HuggingFace Transformers (Greedy Decoding)<a href="#test-1-huggingface-transformers-greedy-decoding" class="hash-link" aria-label="Direct link to Test 1: HuggingFace Transformers (Greedy Decoding)" title="Direct link to Test 1: HuggingFace Transformers (Greedy Decoding)" translate="no">​</a></h3>
<p><strong>Framework:</strong> Special BitNet fork (commit 096f25ae), bfloat16, CPU-only.</p>
<p>The framework issued a warning: &quot;You don&#x27;t have a GPU available to load the model, the inference will be slow because of weight unpacking.&quot;</p>
<table><thead><tr><th>Prompt</th><th>Output</th><th>Speed</th></tr></thead><tbody><tr><td>&quot;The capital of France is&quot;</td><td>&quot;the most of the of the of the of the...&quot;</td><td>0.23 tok/s</td></tr><tr><td>&quot;Hello, my name is&quot;</td><td>&quot;a a a a a a a a a a a a a a a...&quot;</td><td>0.18 tok/s</td></tr><tr><td>&quot;2 + 2 equals&quot;</td><td>&quot;<em>T_1_1_1_1_1_1_1_1_1_1_1_1</em>&quot;</td><td>0.17 tok/s</td></tr></tbody></table>
<p><strong>Result:</strong> Incoherent output. Repetitive tokens with no semantic content.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="test-2-huggingface-transformers-chat-template-with-sampling">Test 2: HuggingFace Transformers (Chat Template with Sampling)<a href="#test-2-huggingface-transformers-chat-template-with-sampling" class="hash-link" aria-label="Direct link to Test 2: HuggingFace Transformers (Chat Template with Sampling)" title="Direct link to Test 2: HuggingFace Transformers (Chat Template with Sampling)" translate="no">​</a></h3>
<p><strong>Settings:</strong> Chat template applied, do_sample=True, temperature=0.6, top_p=0.9.</p>
<table><thead><tr><th>Prompt</th><th>Output</th></tr></thead><tbody><tr><td>&quot;What is the capital of France?&quot;</td><td>Multilingual noise: random tokens from multiple languages with no coherent structure</td></tr></tbody></table>
<p><strong>Result:</strong> Incoherent output. Random subword tokens concatenated without meaning.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="test-3-bitnetcpp-official-microsoft-framework">Test 3: bitnet.cpp (Official Microsoft Framework)<a href="#test-3-bitnetcpp-official-microsoft-framework" class="hash-link" aria-label="Direct link to Test 3: bitnet.cpp (Official Microsoft Framework)" title="Direct link to Test 3: bitnet.cpp (Official Microsoft Framework)" translate="no">​</a></h3>
<p><strong>Build:</strong> Clang 18.1.8, ARM64 NEON, I2_S kernel, no BLAS or Metal acceleration.</p>
<p>The framework issued a critical warning during model loading:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm_load_vocab: missing pre-tokenizer type, using: &#x27;default&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm_load_vocab: CONSIDER REGENERATING THE MODEL</span><br></span></code></pre></div></div>
<table><thead><tr><th>Prompt</th><th>Output</th><th>Speed</th></tr></thead><tbody><tr><td>&quot;The capital of France is&quot;</td><td>Random English subword fragments concatenated without meaning</td><td>0.25 tok/s</td></tr></tbody></table>
<p>Chat mode testing (10+ exchanges) produced similar results: random word fragments with no coherent responses.</p>
<p><strong>Result:</strong> Incoherent output. The tokenizer warning suggests the GGUF file has incorrect metadata.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="performance-summary">Performance Summary<a href="#performance-summary" class="hash-link" aria-label="Direct link to Performance Summary" title="Direct link to Performance Summary" translate="no">​</a></h2>
<table><thead><tr><th>Framework</th><th>Speed (tok/s)</th><th>Memory</th><th>Output Quality</th></tr></thead><tbody><tr><td>HuggingFace (greedy)</td><td>0.17-0.23</td><td>~4 GB</td><td>Incoherent</td></tr><tr><td>HuggingFace (sampling)</td><td>~0.2</td><td>~4 GB</td><td>Incoherent</td></tr><tr><td>bitnet.cpp (I2_S)</td><td>0.25</td><td>1.3 GB</td><td>Incoherent</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="root-cause-analysis">Root Cause Analysis<a href="#root-cause-analysis" class="hash-link" aria-label="Direct link to Root Cause Analysis" title="Direct link to Root Cause Analysis" translate="no">​</a></h2>
<p>Four hypotheses were evaluated:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hypothesis-1-cpu-weight-unpacking-bug-huggingface">Hypothesis 1: CPU Weight Unpacking Bug (HuggingFace)<a href="#hypothesis-1-cpu-weight-unpacking-bug-huggingface" class="hash-link" aria-label="Direct link to Hypothesis 1: CPU Weight Unpacking Bug (HuggingFace)" title="Direct link to Hypothesis 1: CPU Weight Unpacking Bug (HuggingFace)" translate="no">​</a></h3>
<p>The HuggingFace framework warned that inference without GPU would be slow &quot;because of weight unpacking.&quot; Packed 1.58-bit weights may not unpack correctly without GPU kernels. This is plausible for HuggingFace but does not explain the bitnet.cpp results, which have native CPU I2_S support.</p>
<p><strong>Status:</strong> Plausible partial cause.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hypothesis-2-gguf-tokenizer-metadata-error-bitnetcpp">Hypothesis 2: GGUF Tokenizer Metadata Error (bitnet.cpp)<a href="#hypothesis-2-gguf-tokenizer-metadata-error-bitnetcpp" class="hash-link" aria-label="Direct link to Hypothesis 2: GGUF Tokenizer Metadata Error (bitnet.cpp)" title="Direct link to Hypothesis 2: GGUF Tokenizer Metadata Error (bitnet.cpp)" translate="no">​</a></h3>
<p>The bitnet.cpp framework explicitly warned about a &quot;missing pre-tokenizer type&quot; and degraded generation quality. The GGUF file from <code>microsoft/BitNet-b1.58-2B-4T-gguf</code> appears to be missing the correct tokenizer configuration.</p>
<p><strong>Status:</strong> Likely primary cause. A tokenizer mismatch would explain why the model produces random subword fragments -- the decoding step maps token IDs to incorrect text.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hypothesis-3-arm-kernel-issue">Hypothesis 3: ARM Kernel Issue<a href="#hypothesis-3-arm-kernel-issue" class="hash-link" aria-label="Direct link to Hypothesis 3: ARM Kernel Issue" title="Direct link to Hypothesis 3: ARM Kernel Issue" translate="no">​</a></h3>
<p>The I2_S kernel on ARM may contain a bug. However, Microsoft&#x27;s own demos show the model working on Apple M2 hardware, making a fundamental kernel bug unlikely.</p>
<p><strong>Status:</strong> Unlikely.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hypothesis-4-gguf-version-mismatch">Hypothesis 4: GGUF Version Mismatch<a href="#hypothesis-4-gguf-version-mismatch" class="hash-link" aria-label="Direct link to Hypothesis 4: GGUF Version Mismatch" title="Direct link to Hypothesis 4: GGUF Version Mismatch" translate="no">​</a></h3>
<p>The GGUF file uses format V3 with quantization version 2. The bitnet.cpp fork of llama.cpp may expect a different format version.</p>
<p><strong>Status:</strong> Possible but less likely than Hypothesis 2.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="most-likely-root-cause">Most Likely Root Cause<a href="#most-likely-root-cause" class="hash-link" aria-label="Direct link to Most Likely Root Cause" title="Direct link to Most Likely Root Cause" translate="no">​</a></h3>
<p>The GGUF tokenizer metadata is incorrect (missing pre-tokenizer type). The GGUF file distributed through the official HuggingFace repository needs to be regenerated with the correct LLaMA 3 BPE tokenizer settings. This single issue could explain incoherent output across all frameworks, since incorrect tokenization corrupts both input processing and output decoding.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="comparison-across-all-models-tested">Comparison Across All Models Tested<a href="#comparison-across-all-models-tested" class="hash-link" aria-label="Direct link to Comparison Across All Models Tested" title="Direct link to Comparison Across All Models Tested" translate="no">​</a></h2>
<table><thead><tr><th>Model</th><th>Framework</th><th>CPU Result</th><th>GPU Result</th><th>Assessment</th></tr></thead><tbody><tr><td>1bitLLM/bitnet_b1_58-large</td><td>Zig (custom)</td><td>Not tested</td><td>Incoherent (RTX 4090)</td><td>Model-level issue</td></tr><tr><td>1bitLLM/bitnet_b1_58-large</td><td>HuggingFace</td><td>Not tested</td><td>Incoherent (RTX 4090)</td><td>Model-level issue</td></tr><tr><td>microsoft/bitnet-b1.58-2B-4T</td><td>HuggingFace</td><td>Incoherent</td><td>Not tested</td><td>CPU/tokenizer issue</td></tr><tr><td>microsoft/bitnet-b1.58-2B-4T</td><td>bitnet.cpp</td><td>Incoherent</td><td>Not tested</td><td>Tokenizer issue</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="recommendations">Recommendations<a href="#recommendations" class="hash-link" aria-label="Direct link to Recommendations" title="Direct link to Recommendations" translate="no">​</a></h2>
<ol>
<li class=""><strong>Regenerate the GGUF file</strong> from the safetensors weights with correct tokenizer metadata, specifically including the LLaMA 3 BPE pre-tokenizer type.</li>
<li class=""><strong>Test on GPU</strong> using RunPod (RTX 4090 or A100) with HuggingFace Transformers to isolate whether the issue is CPU-specific weight unpacking or a broader model/tokenizer problem.</li>
<li class=""><strong>File an issue</strong> on the Microsoft BitNet repository regarding the GGUF tokenizer warning.</li>
<li class=""><strong>Try the TL1 kernel</strong> instead of I2_S on ARM to rule out kernel-specific issues.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="infrastructure-notes">Infrastructure Notes<a href="#infrastructure-notes" class="hash-link" aria-label="Direct link to Infrastructure Notes" title="Direct link to Infrastructure Notes" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-files">Model Files<a href="#model-files" class="hash-link" aria-label="Direct link to Model Files" title="Direct link to Model Files" translate="no">​</a></h3>
<p>The following model files were used in testing:</p>
<ul>
<li class=""><code>bitnet-cpp/models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf</code> (1.10 GiB) -- GGUF format for bitnet.cpp</li>
<li class=""><code>models/microsoft-bitnet-2b/model.safetensors</code> (1.18 GB) -- SafeTensors format for HuggingFace</li>
<li class=""><code>models/microsoft-bitnet-2b/tokenizer.json</code> (8.7 MB) -- LLaMA 3 tokenizer</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="build-tools">Build Tools<a href="#build-tools" class="hash-link" aria-label="Direct link to Build Tools" title="Direct link to Build Tools" translate="no">​</a></h3>
<ul>
<li class=""><code>bitnet-cpp/build/bin/llama-cli</code> -- Built for ARM64 with Clang 18.1.8</li>
<li class="">Python environments: conda <code>bitnet-cpp</code> (Python 3.9), system Python 3.12</li>
<li class="">HuggingFace Transformers: BitNet fork (commit 096f25ae)</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="update-gpu-results-runpod-rtx-4090">Update: GPU Results (RunPod RTX 4090)<a href="#update-gpu-results-runpod-rtx-4090" class="hash-link" aria-label="Direct link to Update: GPU Results (RunPod RTX 4090)" title="Direct link to Update: GPU Results (RunPod RTX 4090)" translate="no">​</a></h2>
<p>Subsequent testing on a RunPod RTX 4090 instance using bitnet.cpp produced coherent output, confirming that the CPU-only incoherence was environment-specific (likely the GGUF tokenizer metadata issue identified above).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="coherent-generation-samples-bitnetcpp-rtx-4090">Coherent Generation Samples (bitnet.cpp, RTX 4090)<a href="#coherent-generation-samples-bitnetcpp-rtx-4090" class="hash-link" aria-label="Direct link to Coherent Generation Samples (bitnet.cpp, RTX 4090)" title="Direct link to Coherent Generation Samples (bitnet.cpp, RTX 4090)" translate="no">​</a></h3>
<table><thead><tr><th>Prompt</th><th>Output</th><th>Coherent</th></tr></thead><tbody><tr><td>&quot;The future of artificial intelligence is&quot;</td><td>&quot;both fascinating and frightening&quot;</td><td>Yes</td></tr><tr><td>&quot;Hello, I am a 1-bit language model called BitNet. I can&quot;</td><td>&quot;understand and respond to&quot;</td><td>Yes</td></tr><tr><td>&quot;Explain what makes BitNet special:&quot;</td><td>&quot;1) more efficient in&quot;</td><td>Yes</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="gpu-performance">GPU Performance<a href="#gpu-performance" class="hash-link" aria-label="Direct link to GPU Performance" title="Direct link to GPU Performance" translate="no">​</a></h3>
<table><thead><tr><th>Metric</th><th>Value</th></tr></thead><tbody><tr><td>Prompt processing (pp64)</td><td>1.88 tok/s</td></tr><tr><td>Token generation</td><td>~0.25 tok/s</td></tr><tr><td>Memory usage</td><td>1.1 GB model + 300 MB KV cache</td></tr><tr><td>Platform</td><td>CPU-only I2_S kernel (GPU offload not yet available for I2_S)</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>These throughput numbers reflect CPU-only inference even on the GPU instance, because the I2_S quantization kernel does not yet support GPU offload. The high-throughput numbers reported on the <a class="" href="/trinity/docs/docs/benchmarks/gpu-inference">GPU Inference Benchmarks</a> page (298K tok/s on RTX 3090) are from the bitnet.cpp benchmarking mode, which measures kernel throughput rather than end-to-end text generation speed.</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>BitNet b1.58-2B-4T produced incoherent output on CPU hardware across all tested frameworks. The most likely root cause is incorrect tokenizer metadata in the distributed GGUF file. Testing on RunPod RTX 4090 with bitnet.cpp confirmed coherent text generation is achievable. CPU-specific issues remain under investigation.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/gHashTag/trinity/tree/main/docsite/docs/research/bitnet-report.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/trinity/docs/research"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Research and References</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/trinity/docs/research/trinity-node-ffi"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Trinity Node BitNet FFI Integration</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#academic-references" class="table-of-contents__link toc-highlight">Academic References</a></li><li><a href="#model-specifications" class="table-of-contents__link toc-highlight">Model Specifications</a></li><li><a href="#test-environment" class="table-of-contents__link toc-highlight">Test Environment</a></li><li><a href="#test-results" class="table-of-contents__link toc-highlight">Test Results</a><ul><li><a href="#test-1-huggingface-transformers-greedy-decoding" class="table-of-contents__link toc-highlight">Test 1: HuggingFace Transformers (Greedy Decoding)</a></li><li><a href="#test-2-huggingface-transformers-chat-template-with-sampling" class="table-of-contents__link toc-highlight">Test 2: HuggingFace Transformers (Chat Template with Sampling)</a></li><li><a href="#test-3-bitnetcpp-official-microsoft-framework" class="table-of-contents__link toc-highlight">Test 3: bitnet.cpp (Official Microsoft Framework)</a></li></ul></li><li><a href="#performance-summary" class="table-of-contents__link toc-highlight">Performance Summary</a></li><li><a href="#root-cause-analysis" class="table-of-contents__link toc-highlight">Root Cause Analysis</a><ul><li><a href="#hypothesis-1-cpu-weight-unpacking-bug-huggingface" class="table-of-contents__link toc-highlight">Hypothesis 1: CPU Weight Unpacking Bug (HuggingFace)</a></li><li><a href="#hypothesis-2-gguf-tokenizer-metadata-error-bitnetcpp" class="table-of-contents__link toc-highlight">Hypothesis 2: GGUF Tokenizer Metadata Error (bitnet.cpp)</a></li><li><a href="#hypothesis-3-arm-kernel-issue" class="table-of-contents__link toc-highlight">Hypothesis 3: ARM Kernel Issue</a></li><li><a href="#hypothesis-4-gguf-version-mismatch" class="table-of-contents__link toc-highlight">Hypothesis 4: GGUF Version Mismatch</a></li><li><a href="#most-likely-root-cause" class="table-of-contents__link toc-highlight">Most Likely Root Cause</a></li></ul></li><li><a href="#comparison-across-all-models-tested" class="table-of-contents__link toc-highlight">Comparison Across All Models Tested</a></li><li><a href="#recommendations" class="table-of-contents__link toc-highlight">Recommendations</a></li><li><a href="#infrastructure-notes" class="table-of-contents__link toc-highlight">Infrastructure Notes</a><ul><li><a href="#model-files" class="table-of-contents__link toc-highlight">Model Files</a></li><li><a href="#build-tools" class="table-of-contents__link toc-highlight">Build Tools</a></li></ul></li><li><a href="#update-gpu-results-runpod-rtx-4090" class="table-of-contents__link toc-highlight">Update: GPU Results (RunPod RTX 4090)</a><ul><li><a href="#coherent-generation-samples-bitnetcpp-rtx-4090" class="table-of-contents__link toc-highlight">Coherent Generation Samples (bitnet.cpp, RTX 4090)</a></li><li><a href="#gpu-performance" class="table-of-contents__link toc-highlight">GPU Performance</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/getting-started/quickstart">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/api">API Reference</a></li><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/troubleshooting">Troubleshooting</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/gHashTag/trinity" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/gHashTag/trinity/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issues<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/contributing">Contributing</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Trinity Project. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>