<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bitnet/inference" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Inference Pipeline | Trinity</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://gHashTag.github.io/trinity/docs/img/trinity-social-card.png"><meta data-rh="true" name="twitter:image" content="https://gHashTag.github.io/trinity/docs/img/trinity-social-card.png"><meta data-rh="true" property="og:url" content="https://gHashTag.github.io/trinity/docs/bitnet/inference"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Inference Pipeline | Trinity"><meta data-rh="true" name="description" content="This page provides a detailed walkthrough of how BitNet inference works in Trinity, from loading a model file to generating text output. The entire pipeline is implemented natively in Zig with zero external dependencies."><meta data-rh="true" property="og:description" content="This page provides a detailed walkthrough of how BitNet inference works in Trinity, from loading a model file to generating text output. The entire pipeline is implemented natively in Zig with zero external dependencies."><link data-rh="true" rel="icon" href="/trinity/docs/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://gHashTag.github.io/trinity/docs/bitnet/inference"><link data-rh="true" rel="alternate" href="https://gHashTag.github.io/trinity/docs/bitnet/inference" hreflang="en"><link data-rh="true" rel="alternate" href="https://gHashTag.github.io/trinity/docs/bitnet/inference" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Inference Pipeline","item":"https://gHashTag.github.io/trinity/docs/bitnet/inference"}]}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"><link rel="stylesheet" href="/trinity/docs/assets/css/styles.469fa185.css">
<script src="/trinity/docs/assets/js/runtime~main.216a3093.js" defer="defer"></script>
<script src="/trinity/docs/assets/js/main.dc1b2c94.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/trinity/docs/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/trinity/docs/"><div class="navbar__logo"><img src="/trinity/docs/img/logo.svg" alt="Trinity Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/trinity/docs/img/logo.svg" alt="Trinity Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Trinity</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/trinity/docs/">Documentation</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/gHashTag/trinity" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/"><span title="Trinity Documentation" class="linkLabel_WmDU">Trinity Documentation</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/overview/introduction"><span title="Overview" class="categoryLinkLabel_W154">Overview</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/getting-started/quickstart"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/concepts"><span title="Concepts" class="categoryLinkLabel_W154">Concepts</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/trinity/docs/bitnet"><span title="BitNet Integration" class="categoryLinkLabel_W154">BitNet Integration</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/bitnet"><span title="BitNet Integration" class="linkLabel_WmDU">BitNet Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/trinity/docs/bitnet/inference"><span title="Inference Pipeline" class="linkLabel_WmDU">Inference Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/trinity/docs/bitnet/model-format"><span title="GGUF Model Format" class="linkLabel_WmDU">GGUF Model Format</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/hdc"><span title="HDC Applications" class="categoryLinkLabel_W154">HDC Applications</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/vibee"><span title="VIBEE Language" class="categoryLinkLabel_W154">VIBEE Language</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/benchmarks"><span title="Benchmarks" class="categoryLinkLabel_W154">Benchmarks</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/deployment"><span title="Deployment" class="categoryLinkLabel_W154">Deployment</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/api"><span title="API Reference" class="categoryLinkLabel_W154">API Reference</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/architecture/overview"><span title="Architecture" class="categoryLinkLabel_W154">Architecture</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/math-foundations"><span title="Mathematical Foundations" class="categoryLinkLabel_W154">Mathematical Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/trinity/docs/research"><span title="Research" class="categoryLinkLabel_W154">Research</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/faq"><span title="FAQ" class="linkLabel_WmDU">FAQ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/trinity/docs/contributing"><span title="Contributing to Trinity" class="linkLabel_WmDU">Contributing to Trinity</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/trinity/docs/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">BitNet Integration</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Inference Pipeline</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Inference Pipeline</h1></header>
<p>This page provides a detailed walkthrough of how BitNet inference works in Trinity, from loading a model file to generating text output. The entire pipeline is implemented natively in Zig with zero external dependencies.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-model-loading----gguf-format-reader">1. Model Loading -- GGUF Format Reader<a href="#1-model-loading----gguf-format-reader" class="hash-link" aria-label="Direct link to 1. Model Loading -- GGUF Format Reader" title="Direct link to 1. Model Loading -- GGUF Format Reader" translate="no">​</a></h2>
<p>The inference pipeline begins with loading a pre-quantized model from a GGUF v3 file. Trinity&#x27;s <code>gguf_reader.zig</code> module handles this process:</p>
<ul>
<li class="">Validates the GGUF magic bytes (<code>0x46554747</code>, which is &quot;GGUF&quot; in little-endian) and version number.</li>
<li class="">Parses the metadata header to extract model architecture parameters: number of layers, attention heads, hidden dimensions, vocabulary size, RoPE theta, and normalization epsilon.</li>
<li class="">Reads tensor descriptors that specify the name, shape, quantization type, and byte offset for each weight tensor in the file.</li>
<li class="">Maps tensor data into memory. For BitNet models, weight tensors use the I2_S quantization type, which packs 4 ternary values per byte (2 bits each, where <code>00</code> = 0, <code>01</code> = +1, <code>10</code> = -1).</li>
</ul>
<p>The model configuration for the BitNet 2B architecture defaults to:</p>
<table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>Vocabulary size</td><td>128,256</td></tr><tr><td>Hidden size</td><td>2,560</td></tr><tr><td>Intermediate size</td><td>6,912</td></tr><tr><td>Number of layers</td><td>30</td></tr><tr><td>Attention heads</td><td>20</td></tr><tr><td>Key-value heads</td><td>5</td></tr><tr><td>Max context length</td><td>4,096</td></tr><tr><td>RoPE theta</td><td>500,000</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-tokenization----sentencepiece-bpe">2. Tokenization -- SentencePiece BPE<a href="#2-tokenization----sentencepiece-bpe" class="hash-link" aria-label="Direct link to 2. Tokenization -- SentencePiece BPE" title="Direct link to 2. Tokenization -- SentencePiece BPE" translate="no">​</a></h2>
<p>Input text is converted to token IDs using the SentencePiece BPE tokenizer:</p>
<ul>
<li class="">The tokenizer loads a vocabulary file (JSON format) containing token-to-ID mappings and special tokens.</li>
<li class="">It supports both SentencePiece-style space markers (U+2581) and GPT-2-style markers (U+0120), auto-detecting the convention used by the model.</li>
<li class="">Text is preprocessed by prepending a space marker and replacing internal spaces with the marker character.</li>
<li class="">Encoding uses a greedy longest-match algorithm: at each position, the tokenizer tries the longest possible substring first and works downward until it finds a match in the vocabulary.</li>
<li class="">For bytes not covered by any vocabulary entry, the tokenizer falls back to byte-level encoding using <code>&lt;0xNN&gt;</code> tokens.</li>
<li class="">A BOS (beginning-of-sequence) token is prepended to every encoded sequence.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-embedding----token-to-vector-lookup">3. Embedding -- Token to Vector Lookup<a href="#3-embedding----token-to-vector-lookup" class="hash-link" aria-label="Direct link to 3. Embedding -- Token to Vector Lookup" title="Direct link to 3. Embedding -- Token to Vector Lookup" translate="no">​</a></h2>
<p>Each token ID is mapped to a dense vector of size 2560 (the hidden dimension) through an embedding table lookup. The embedding weights are stored in the GGUF file as part of the model tensors. This lookup produces the initial hidden state that will be processed by the transformer layers.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-transformer-layers----30-layer-processing">4. Transformer Layers -- 30-Layer Processing<a href="#4-transformer-layers----30-layer-processing" class="hash-link" aria-label="Direct link to 4. Transformer Layers -- 30-Layer Processing" title="Direct link to 4. Transformer Layers -- 30-Layer Processing" translate="no">​</a></h2>
<p>The hidden state passes through 30 identical transformer layers. Each layer performs the following operations in sequence:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rmsnorm-input-normalization">RMSNorm (Input Normalization)<a href="#rmsnorm-input-normalization" class="hash-link" aria-label="Direct link to RMSNorm (Input Normalization)" title="Direct link to RMSNorm (Input Normalization)" translate="no">​</a></h3>
<p>Root Mean Square normalization is applied before attention:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">rms = sqrt(mean(x^2) + eps)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output = (x / rms) * weight</span><br></span></code></pre></div></div>
<p>The epsilon value is set to 1e-5 to prevent division by zero.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grouped-query-attention-gqa">Grouped Query Attention (GQA)<a href="#grouped-query-attention-gqa" class="hash-link" aria-label="Direct link to Grouped Query Attention (GQA)" title="Direct link to Grouped Query Attention (GQA)" translate="no">​</a></h3>
<p>The attention mechanism uses 20 query heads and 5 key-value heads (a 4:1 grouping ratio):</p>
<ul>
<li class=""><strong>Q/K/V Projections</strong>: The normalized hidden state is projected through ternary weight matrices to produce query (Q), key (K), and value (V) vectors. These projections use the ternary matrix-vector multiply, which replaces multiplication with conditional addition and subtraction.</li>
<li class=""><strong>Rotary Position Embeddings (RoPE)</strong>: Positional information is injected into Q and K vectors using rotary embeddings with theta=500000. This allows the model to understand token positions without explicit position embeddings.</li>
<li class=""><strong>KV-Cache</strong>: Key and value vectors are stored in a per-layer cache to avoid recomputation during autoregressive generation. The cache stores <code>[layer][position][kv_head][head_dim]</code> and supports sequences up to the maximum context length.</li>
<li class=""><strong>Scaled Dot-Product Attention</strong>: For each query head, attention scores are computed against all cached key vectors, scaled by <code>1/sqrt(head_dim)</code>, passed through softmax, and used to weight the value vectors. Each group of 4 query heads shares the same KV head.</li>
<li class=""><strong>Output Projection</strong>: The concatenated attention output is projected back to the hidden dimension through a ternary weight matrix.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="residual-connection">Residual Connection<a href="#residual-connection" class="hash-link" aria-label="Direct link to Residual Connection" title="Direct link to Residual Connection" translate="no">​</a></h3>
<p>The attention output is added to the original input (skip connection).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rmsnorm-post-attention-normalization">RMSNorm (Post-Attention Normalization)<a href="#rmsnorm-post-attention-normalization" class="hash-link" aria-label="Direct link to RMSNorm (Post-Attention Normalization)" title="Direct link to RMSNorm (Post-Attention Normalization)" translate="no">​</a></h3>
<p>A second RMSNorm is applied before the feed-forward network.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="feed-forward-network-ffn">Feed-Forward Network (FFN)<a href="#feed-forward-network-ffn" class="hash-link" aria-label="Direct link to Feed-Forward Network (FFN)" title="Direct link to Feed-Forward Network (FFN)" translate="no">​</a></h3>
<p>The FFN uses a gated architecture with three ternary projections:</p>
<ul>
<li class=""><strong>Gate projection</strong>: hidden_size (2560) to intermediate_size (6912)</li>
<li class=""><strong>Up projection</strong>: hidden_size (2560) to intermediate_size (6912)</li>
<li class=""><strong>Activation</strong>: The gate output is passed through squared ReLU: <code>relu2(x) = max(0, x)^2</code></li>
<li class=""><strong>Element-wise multiply</strong>: gate_activated * up_output</li>
<li class=""><strong>Down projection</strong>: intermediate_size (6912) back to hidden_size (2560)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="residual-connection-1">Residual Connection<a href="#residual-connection-1" class="hash-link" aria-label="Direct link to Residual Connection" title="Direct link to Residual Connection" translate="no">​</a></h3>
<p>The FFN output is added to the post-attention hidden state.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-output----token-generation">5. Output -- Token Generation<a href="#5-output----token-generation" class="hash-link" aria-label="Direct link to 5. Output -- Token Generation" title="Direct link to 5. Output -- Token Generation" translate="no">​</a></h2>
<p>After all 30 layers have processed the hidden state:</p>
<ol>
<li class=""><strong>Final RMSNorm</strong>: The output hidden state is normalized one last time.</li>
<li class=""><strong>Logits Computation</strong>: The normalized hidden state is projected against the output embedding matrix to produce logits over the full vocabulary (128,256 scores).</li>
<li class=""><strong>Temperature Sampling</strong>: Logits are divided by a temperature parameter, then softmax is applied to produce a probability distribution. A token is sampled from this distribution.</li>
<li class=""><strong>Token Decoding</strong>: The sampled token ID is converted back to text using the tokenizer&#x27;s reverse vocabulary. Space markers are replaced with actual spaces, and special tokens are handled appropriately.</li>
<li class=""><strong>Autoregressive Loop</strong>: The generated token is fed back as input, its KV representations are cached, and the process repeats until an EOS token is generated or the maximum length is reached.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="cli-usage">CLI Usage<a href="#cli-usage" class="hash-link" aria-label="Direct link to CLI Usage" title="Direct link to CLI Usage" translate="no">​</a></h2>
<p>Trinity provides two interfaces for BitNet inference:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="interactive-chat">Interactive Chat<a href="#interactive-chat" class="hash-link" aria-label="Direct link to Interactive Chat" title="Direct link to Interactive Chat" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/vibee chat </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--model</span><span class="token plain"> path/to/bitnet-2b.gguf</span><br></span></code></pre></div></div>
<p>This starts an interactive session where you can type prompts and receive generated responses.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="http-api-server">HTTP API Server<a href="#http-api-server" class="hash-link" aria-label="Direct link to HTTP API Server" title="Direct link to HTTP API Server" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/vibee serve </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--port</span><span class="token plain"> </span><span class="token number">8080</span><br></span></code></pre></div></div>
<p>This launches an HTTP server that accepts inference requests, suitable for integration with other applications or services.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="performance-characteristics">Performance Characteristics<a href="#performance-characteristics" class="hash-link" aria-label="Direct link to Performance Characteristics" title="Direct link to Performance Characteristics" translate="no">​</a></h2>
<p>Because all weight matrices use ternary values, the dominant computation in each layer is the ternary matrix-vector multiply. This operation processes 4 trits per byte using a lookup table, replacing floating-point multiplication with conditional addition. The SIMD-optimized variant (<code>ternaryMatVecSIMD</code>) processes 8 elements at a time using vector instructions. The KV-cache ensures that each new token only requires a single forward pass through all layers, rather than reprocessing the entire sequence.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/gHashTag/trinity/tree/main/docsite/docs/bitnet/inference.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/trinity/docs/bitnet"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">BitNet Integration</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/trinity/docs/bitnet/model-format"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">GGUF Model Format</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-model-loading----gguf-format-reader" class="table-of-contents__link toc-highlight">1. Model Loading -- GGUF Format Reader</a></li><li><a href="#2-tokenization----sentencepiece-bpe" class="table-of-contents__link toc-highlight">2. Tokenization -- SentencePiece BPE</a></li><li><a href="#3-embedding----token-to-vector-lookup" class="table-of-contents__link toc-highlight">3. Embedding -- Token to Vector Lookup</a></li><li><a href="#4-transformer-layers----30-layer-processing" class="table-of-contents__link toc-highlight">4. Transformer Layers -- 30-Layer Processing</a><ul><li><a href="#rmsnorm-input-normalization" class="table-of-contents__link toc-highlight">RMSNorm (Input Normalization)</a></li><li><a href="#grouped-query-attention-gqa" class="table-of-contents__link toc-highlight">Grouped Query Attention (GQA)</a></li><li><a href="#residual-connection" class="table-of-contents__link toc-highlight">Residual Connection</a></li><li><a href="#rmsnorm-post-attention-normalization" class="table-of-contents__link toc-highlight">RMSNorm (Post-Attention Normalization)</a></li><li><a href="#feed-forward-network-ffn" class="table-of-contents__link toc-highlight">Feed-Forward Network (FFN)</a></li><li><a href="#residual-connection-1" class="table-of-contents__link toc-highlight">Residual Connection</a></li></ul></li><li><a href="#5-output----token-generation" class="table-of-contents__link toc-highlight">5. Output -- Token Generation</a></li><li><a href="#cli-usage" class="table-of-contents__link toc-highlight">CLI Usage</a><ul><li><a href="#interactive-chat" class="table-of-contents__link toc-highlight">Interactive Chat</a></li><li><a href="#http-api-server" class="table-of-contents__link toc-highlight">HTTP API Server</a></li></ul></li><li><a href="#performance-characteristics" class="table-of-contents__link toc-highlight">Performance Characteristics</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/getting-started/quickstart">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/api">API Reference</a></li><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/troubleshooting">Troubleshooting</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/gHashTag/trinity" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/gHashTag/trinity/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issues<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/trinity/docs/contributing">Contributing</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 Trinity Project. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>